{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T21:42:02.365577Z",
     "start_time": "2019-06-10T21:42:02.362574Z"
    }
   },
   "outputs": [],
   "source": [
    "from bitstring import * #21\n",
    "from nltk.book import * #24 and following\n",
    "from nltk import edit_distance\n",
    "import random\n",
    "import hashlib\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 31. Generate a set S of n random bitstrings of length 100. Find min x,y sha-1 (x||y), where x||y denotes concatenation of bitstrings x and y. Estimate, what is the maximal n for this task that can be handled by your computer? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T21:11:41.348842Z",
     "start_time": "2019-06-10T21:05:25.876600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6964835999043087099000011901576379229044\n"
     ]
    }
   ],
   "source": [
    "n = 20000\n",
    "def gen_bitstring():\n",
    "    ret = ''\n",
    "    for i in range(100):\n",
    "        ret += str((random.getrandbits(1)))\n",
    "    return ret.encode('latin1')\n",
    "S = []\n",
    "upbound = bytes.fromhex('ffffffffffffffffffffffffffffffffffffffff') #40 hexes = 160 bits\n",
    "for i in range(n):\n",
    "    S.append(gen_bitstring())\n",
    "for i in range(n):\n",
    "    p = hashlib.sha1()\n",
    "    p.update(S[i])\n",
    "    for j in range(i+1, n):\n",
    "        q = p.copy()\n",
    "        q.update(S[j])\n",
    "        q = q.digest()\n",
    "        if q < upbound:\n",
    "            upbound = q\n",
    "print(int.from_bytes(upbound, byteorder='big'))\n",
    "# n = 10, t = 0.007s\n",
    "# n = 100, t = 0.02s\n",
    "# n = 1000, t = 0.978s\n",
    "# n = 10000, t = 1m 33.9s\n",
    "# n = 20000, t = 6m 15s\n",
    "# could be improved with multithreading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 32. (use NLTK). Let Sl, S2, S3 be the sets of all words shorter than 8 letters from textl , text 2, text 3, respectively. Compute signatures for Sl, S2, S3 represented by 100 minhashes and then estimate Jaccard similarity between each pair of Sl , S2, S3. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T22:19:44.107013Z",
     "start_time": "2019-06-10T22:19:36.709714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22580645161290322\n",
      "0.1366906474820144\n",
      "0.17647058823529413\n"
     ]
    }
   ],
   "source": [
    "S1 = set(filter(lambda x: len(x)< 8, set(text1)))\n",
    "S2 = set(filter(lambda x: len(x)< 8, set(text2)))\n",
    "S3 = set(filter(lambda x: len(x)< 8, set(text3)))\n",
    "def isPrime(n):\n",
    "    if n==2 or n==3: return True\n",
    "    if n%2==0 or n<2: return False\n",
    "    for i in range(3,int(n**0.5)+1,2):   # only odd numbers\n",
    "        if n%i==0:\n",
    "            return False    \n",
    "\n",
    "    return True\n",
    "primes = [i for i in range(100000,500000) if isPrime(i)]\n",
    "\n",
    "def get_hash():\n",
    "    prime = primes.pop()\n",
    "    def tmp(x):\n",
    "        return (x*random.randint(1, 1000) + random.randint(1, 1000))%prime\n",
    "    return tmp\n",
    "hashes = [get_hash() for _ in range(100)]\n",
    "S1sig = []\n",
    "for fun in hashes:\n",
    "    upbound = 1000000\n",
    "    for word in S1:\n",
    "        tmp = fun(int.from_bytes(word.encode('latin1'), byteorder='big'))\n",
    "        if tmp < upbound:\n",
    "            upbound = tmp\n",
    "    S1sig.append(upbound)\n",
    "S2sig = []\n",
    "for fun in hashes:\n",
    "    upbound = 1000000\n",
    "    for word in S2:\n",
    "        tmp = fun(int.from_bytes(word.encode('latin1'), byteorder='big'))\n",
    "        if tmp < upbound:\n",
    "            upbound = tmp\n",
    "    S2sig.append(upbound)\n",
    "S3sig = []\n",
    "for fun in hashes:\n",
    "    upbound = 1000000\n",
    "    for word in S3:\n",
    "        tmp = fun(int.from_bytes(word.encode('latin1'), byteorder='big'))\n",
    "        if tmp < upbound:\n",
    "            upbound = tmp\n",
    "    S3sig.append(upbound)\n",
    "S1sig = set(S1sig)\n",
    "S2sig = set(S2sig)\n",
    "S3sig = set(S3sig)\n",
    "print(len(S1sig&S2sig)/len(S1sig|S2sig))\n",
    "print(len(S1sig&S3sig)/len(S1sig|S3sig))\n",
    "print(len(S2sig&S3sig)/len(S2sig|S3sig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33. Compare the results from the previous exercise with the exact Jaccard similarity of sets Sl , S2, S3. What if random permutation of the characteristic matrix rows were replaced with a random mapping? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T22:20:00.772633Z",
     "start_time": "2019-06-10T22:20:00.765627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24746416296420487\n",
      "0.12482041747654864\n",
      "0.20091688259916285\n"
     ]
    }
   ],
   "source": [
    "print(len(S1&S2)/len(S1|S2))\n",
    "print(len(S1&S3)/len(S1|S3))\n",
    "print(len(S2&S3)/len(S2|S3))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
